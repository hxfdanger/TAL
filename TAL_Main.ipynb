{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TAL_Main.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "9ZIQeMVg4uLJ",
        "colab_type": "code",
        "outputId": "2de7300c-c19f-4e8d-8540-379dd9e5acb5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('drive')\n",
        "import os"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at drive; to attempt to forcibly remount, call drive.mount(\"drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "lWZ7Tpi34vl4",
        "colab_type": "code",
        "outputId": "2a0d2bd3-d5bb-4410-9335-b13254553aed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "cell_type": "code",
      "source": [
        "!ls\n",
        "print()\n",
        "!ls drive\n",
        "print()\n",
        "!ls drive/My\\ Drive/M2_IAAA/TAL"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "arbre.py\t     embd.vec\t\t     neural_network.py\tsample_data\n",
            "automate.py\t     embedding.py\t     Oracle.py\t\tutil.py\n",
            "ConstructAllTree.py  f2_tbp.fm\t\t     PP.py\t\tWordBuffer.py\n",
            "create_dicos.py      Features.py\t     Projectivite.py\tWord.py\n",
            "Dicos.py\t     fr_gsd-ud-train.conllu  __pycache__\n",
            "drive\t\t     Main.py\t\t     read_conllu.py\n",
            "\n",
            "'My Drive'\n",
            "\n",
            "arbre.py\t     Dicos.py\t\tOracle.py\t util.py\n",
            "automate.py\t     embedding.py\tPP.py\t\t WordBuffer.py\n",
            "ConstructAllTree.py  Features.py\tProjectivite.py  Word.py\n",
            "create_dicos.py      Main.py\t\tread_conllu.py\n",
            "Data\t\t     neural_network.py\tREADME.md\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "r3nOqI5K5ObL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "8ANtUMmf5CUl",
        "colab_type": "code",
        "outputId": "e1c1d296-af45-4952-da0a-c5f9258ab1b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "from keras.utils.np_utils import to_categorical\n",
        "from sklearn import preprocessing\n",
        "import numpy as np\n",
        "from numpy import argmax\n",
        "from ConstructAllTree import *\n",
        "from Features import *\n",
        "from Oracle import *\n",
        "from neural_network import create_neural_network_model\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "aIeaOy6rAY1l",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_mcd():\n",
        "    mcd = (\n",
        "        ('INDEX', 'INT'), ('FORM', 'INT'), ('LEMMA',\n",
        "                                            'INT'), ('POS', 'SYM'), ('X1', 'INT'), ('MORPHO', 'INT'),\n",
        "        ('GOV', 'SYM'), ('LABEL', 'SYM'), ('X2', 'SYM'), ('X3', 'SYM'))\n",
        "\n",
        "    return mcd\n",
        "\n",
        "\n",
        "def set_mcd(mcd):\n",
        "    mcd = mcd\n",
        "\n",
        "\n",
        "def get_xy(file_conllu, file_features, file_embedding=None):\n",
        "    mcd = get_mcd()\n",
        "\n",
        "    print(\"Chargement des arbres\")\n",
        "    obj_generateAlltree = ConstructAllTree(file_conllu, mcd, True)\n",
        "\n",
        "    all_tree = obj_generateAlltree.get_allTreeProjectiviser()\n",
        "    # print(all_tree[0].print_tree())\n",
        "    print(\"Arbres charger : \", len(all_tree))\n",
        "\n",
        "    print(\"Création du dataset\")\n",
        "    features = Features(file_features)\n",
        "    i = 0\n",
        "    for tree in all_tree:\n",
        "        i += 1\n",
        "        if i % 1000 == 0:\n",
        "            print(i)\n",
        "        # tree.print_tree()\n",
        "        # if i != 43 and i != 61:\n",
        "        A = Oracle(tree, features)\n",
        "        A.run()\n",
        "\n",
        "    print(\"Convertion du dataset\")\n",
        "    print(\"file_embedding : \", file_embedding)\n",
        "    X, Y = features.get_Data_Set(file_embedding)\n",
        "    \"\"\"X_onehot = features.convert_datas_to_one_hot()\n",
        "\n",
        "\tY_onehot = features.convert_labels_to_one_hot()\"\"\"\n",
        "    return X, Y\n",
        "\n",
        "\n",
        "def get_data(file_features, file_train_conllu, file_embedding=None):\n",
        "\n",
        "    x_train, y_train = get_xy(file_train_conllu, file_features, file_embedding)\n",
        "\n",
        "    return x_train, y_train\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jwefjKNVIUDC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "features_file = \"drive/My Drive/M2_IAAA/TAL/Data/f2_tbp.fm\"\n",
        "conllu_file = \"drive/My Drive/M2_IAAA/TAL/Data/fr_gsd-ud-train.conllu\"\n",
        "weight_embedding_file = \"drive/My Drive/M2_IAAA/TAL/Data/embd__fr_50.vec\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fU8aY_HE5ePa",
        "colab_type": "code",
        "outputId": "76137580-c7b1-4623-e756-45cbc47faa8f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        }
      },
      "cell_type": "code",
      "source": [
        "x_train, y_train = get_data(features_file, conllu_file, weight_embedding_file)\n",
        "# x_train,x_test,y_train,y_test = get_data(\"Data/f1_tbp.fm\",\"test.txt\",\"test.txt\")\n",
        "print(\"x_train=\", x_train.shape)\n",
        "print(\"Y_train=\", y_train.shape)\n",
        "print(\"start_train\")\n",
        "input_dim = x_train.shape[1]\n",
        "print(\"input_dim= \", input_dim)\n",
        "nb_class = y_train.shape[1]\n",
        "print(\"nb_class= \", nb_class)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Chargement des arbres\n",
            "Arbres charger :  14554\n",
            "Création du dataset\n",
            "Features prise en compte :  [('Pile', 0, 'FORM'), ('Buffer', 0, 'FORM'), ('Pile', 0, 'POS'), ('Pile', 0, 'LEMMA'), ('Pile', 0, 'MORPHO'), ('Buffer', 0, 'POS'), ('Buffer', 0, 'LEMMA'), ('Buffer', 0, 'MORPHO'), ('Buffer', -1, 'POS'), ('Buffer', 1, 'POS'), 'DIST']\n",
            "1000\n",
            "2000\n",
            "3000\n",
            "4000\n",
            "5000\n",
            "6000\n",
            "7000\n",
            "8000\n",
            "9000\n",
            "10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "UnMvSozFE9Cf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model1 = create_neural_network_model(nb_class, input_dim)\n",
        "# Train the model, iterating on the data in batches of 32 samples\n",
        "model.fit(x_train, y_train, epochs=1000)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "chxvFuRkLRrO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.save('model_f2.h5')  # creates a HDF5 file 'my_model.h5'\n",
        "del model  # deletes the existing model\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Gu2AoiStLysI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}